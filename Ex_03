#1

You have trained a linear regression model, and you notice the following:

The model performs very well on the training set but poorly on the validation set

The predictions on the validation set are highly sensitive to small changes in the input data (high variance)

The model seems to be overfitting

Which regularization technique would help reduce the variance and prevent overfitting in this scenario?

Answer:
I would use L2 regularization (Ridge), it shrinks all coefficients, but doesn't zero them out.
Ridge keeps all features, just makes the model more stable.
_____________________________________________________________________________________________
#2

You are working with a linear regression model that includes many input features, and you suspect that some features are irrelevant (they contribute little to the prediction).

You want to:

Reduce the number of features used by the model

Encourage the model to automatically set some coefficients to zero (effectively removing those features)

Which regularization method should you use?

Answer:
I would use L1 regularization (Lasso), it can set some coefficients exactly to 0.
Lasso "selects features" â€” it can automatically ignore irrelevant features.

